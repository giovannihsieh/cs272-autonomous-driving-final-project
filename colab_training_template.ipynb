{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CS272 Autonomous Driving - Emergency Vehicle Yielding Training\n",
        "\n",
        "This notebook trains a PPO agent on a custom emergency vehicle yielding environment.\n",
        "\n",
        "**Setup Steps:**\n",
        "1. Upload `emergency_env.py` to your Google Drive\n",
        "2. Set Runtime → Change runtime type → GPU\n",
        "3. Run cells in order"
      ],
      "metadata": {
        "id": "title"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Install required packages\n",
        "!pip install gymnasium highway-env stable-baselines3[extra] pandas matplotlib tqdm -q\n",
        "\n",
        "# Verify GPU is available\n",
        "import torch\n",
        "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"WARNING: No GPU detected. Training will be slow!\")"
      ],
      "metadata": {
        "id": "setup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# IMPORTANT: Update this path to match your Google Drive folder structure\n",
        "PROJECT_FOLDER = \"/content/drive/MyDrive/CS272_Project\"\n",
        "\n",
        "# Create custom_env module structure\n",
        "os.makedirs('/content/custom_env', exist_ok=True)\n",
        "\n",
        "# Copy emergency_env.py from Drive\n",
        "!cp {PROJECT_FOLDER}/emergency_env.py /content/custom_env/\n",
        "\n",
        "# Create __init__.py to make it a package\n",
        "with open('/content/custom_env/__init__.py', 'w') as f:\n",
        "    f.write('')\n",
        "\n",
        "# Add to Python path\n",
        "sys.path.insert(0, '/content')\n",
        "\n",
        "# Verify import works\n",
        "import custom_env.emergency_env\n",
        "print(\"✓ Custom environment imported successfully!\")"
      ],
      "metadata": {
        "id": "import_env"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import highway_env\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup directories - saves to Google Drive for persistence\n",
        "SAVE_DIR = f\"{PROJECT_FOLDER}/models\"\n",
        "LOG_DIR = f\"{PROJECT_FOLDER}/logs\"\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Models will be saved to: {SAVE_DIR}\")\n",
        "print(f\"Logs will be saved to: {LOG_DIR}\")"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure environment with LiDAR observation\n",
        "config = {\n",
        "    \"observation\": {\n",
        "        \"type\": \"LidarObservation\",\n",
        "        \"cells\": 64,\n",
        "    },\n",
        "    \"action\": {\n",
        "        \"type\": \"DiscreteMetaAction\",\n",
        "    },\n",
        "}\n",
        "\n",
        "def make_env():\n",
        "    env = gym.make(\"EmergencyHighwayEnv-v0\", config=config, render_mode=None)\n",
        "    env = Monitor(env, filename=f\"{LOG_DIR}/monitor_emergency_lidar.csv\")\n",
        "    return env\n",
        "\n",
        "# Test environment creation\n",
        "test_env = make_env()\n",
        "obs, info = test_env.reset()\n",
        "print(f\"✓ Environment created successfully!\")\n",
        "print(f\"Observation shape: {obs.shape}\")\n",
        "print(f\"Action space: {test_env.action_space}\")\n",
        "test_env.close()"
      ],
      "metadata": {
        "id": "create_env"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create vectorized environment\n",
        "venv = DummyVecEnv([make_env])\n",
        "\n",
        "# Checkpoint callback - saves model every 20k steps\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=20_000,\n",
        "    save_path=SAVE_DIR,\n",
        "    name_prefix=\"ppo_emergency_lidar_checkpoint\"\n",
        ")\n",
        "\n",
        "# Evaluation callback - evaluates and saves best model every 25k steps\n",
        "eval_env = DummyVecEnv([make_env])\n",
        "eval_callback = EvalCallback(\n",
        "    eval_env,\n",
        "    best_model_save_path=SAVE_DIR,\n",
        "    log_path=LOG_DIR,\n",
        "    eval_freq=25_000,\n",
        "    deterministic=True,\n",
        "    render=False\n",
        ")\n",
        "\n",
        "# Create PPO model - will use GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Training device: {device}\")\n",
        "\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    venv,\n",
        "    learning_rate=2e-4,\n",
        "    n_steps=2048,\n",
        "    batch_size=256,\n",
        "    n_epochs=5,\n",
        "    gamma=0.99,\n",
        "    gae_lambda=0.95,\n",
        "    clip_range=0.1,\n",
        "    ent_coef=0.001,\n",
        "    vf_coef=0.5,\n",
        "    max_grad_norm=0.5,\n",
        "    verbose=1,\n",
        "    device=device,\n",
        "    tensorboard_log=f\"{LOG_DIR}/tb/\"\n",
        ")\n",
        "\n",
        "print(\"✓ Model created successfully!\")"
      ],
      "metadata": {
        "id": "create_model"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "print(\"Starting training for Emergency Vehicle Yielding Environment (LiDAR)...\")\n",
        "print(\"Training for ~4000 episodes (500,000 timesteps)...\")\n",
        "print(\"This will take approximately 1-2 hours on GPU, 10-20 hours on CPU.\\n\")\n",
        "\n",
        "model.learn(\n",
        "    total_timesteps=500_000,\n",
        "    tb_log_name=\"run_emergency_lidar\",\n",
        "    callback=[checkpoint_callback, eval_callback],\n",
        "    progress_bar=True\n",
        ")\n",
        "\n",
        "# Save final model\n",
        "final_path = f\"{SAVE_DIR}/ppo_emergency_lidar_final\"\n",
        "model.save(final_path)\n",
        "print(f\"\\n✓ Training complete! Model saved to: {final_path}\")"
      ],
      "metadata": {
        "id": "train"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot learning curve\n",
        "def plot_learning_curve(log_path, output_path):\n",
        "    df = pd.read_csv(log_path, skiprows=1)\n",
        "    rewards = df[\"r\"].values\n",
        "    window = 20\n",
        "    smoothed = pd.Series(rewards).rolling(window).mean()\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(rewards, alpha=0.3, label=\"Raw episodic reward\", color='blue')\n",
        "    plt.plot(smoothed, linewidth=2, label=f\"Smoothed (window={window})\", color='orange')\n",
        "    plt.xlabel(\"Episode\")\n",
        "    plt.ylabel(\"Reward\")\n",
        "    plt.title(\"Learning Curve - Emergency Yielding (LiDAR Observation)\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(output_path, dpi=300)\n",
        "    print(f\"Learning curve saved to: {output_path}\")\n",
        "    plt.show()\n",
        "\n",
        "learning_curve_path = f\"{LOG_DIR}/emergency_lidar_learning_curve.png\"\n",
        "plot_learning_curve(f\"{LOG_DIR}/monitor_emergency_lidar.csv\", learning_curve_path)"
      ],
      "metadata": {
        "id": "plot_learning"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model for evaluation\n",
        "print(\"Loading best model for evaluation...\")\n",
        "model = PPO.load(f\"{SAVE_DIR}/best_model\")\n",
        "\n",
        "def evaluate_agent(model, make_env_fn, episodes=500):\n",
        "    returns = []\n",
        "    env = make_env_fn()\n",
        "\n",
        "    for ep in tqdm(range(episodes), desc=\"Evaluating\"):\n",
        "        obs, info = env.reset()\n",
        "        done = truncated = False\n",
        "        total_reward = 0\n",
        "\n",
        "        while not (done or truncated):\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, truncated, info = env.step(action)\n",
        "            total_reward += reward\n",
        "\n",
        "        returns.append(total_reward)\n",
        "\n",
        "    env.close()\n",
        "    return returns\n",
        "\n",
        "print(\"Running 500-episode deterministic evaluation...\")\n",
        "returns = evaluate_agent(model, make_env)\n",
        "\n",
        "print(f\"\\n=== Evaluation Results ===\")\n",
        "print(f\"Mean return: {np.mean(returns):.2f}\")\n",
        "print(f\"Std return: {np.std(returns):.2f}\")\n",
        "print(f\"Min return: {np.min(returns):.2f}\")\n",
        "print(f\"Max return: {np.max(returns):.2f}\")"
      ],
      "metadata": {
        "id": "evaluate"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Violin plot for performance test\n",
        "plt.figure(figsize=(7, 6))\n",
        "parts = plt.violinplot([returns], showmeans=True, showextrema=True)\n",
        "plt.xticks([1], [\"PPO (LiDAR)\"])\n",
        "plt.ylabel(\"Episodic Return\")\n",
        "plt.title(\"Performance Test - Emergency Yielding (LiDAR, 500 episodes)\")\n",
        "plt.grid(axis=\"y\")\n",
        "plt.tight_layout()\n",
        "\n",
        "performance_path = f\"{LOG_DIR}/emergency_lidar_performance_test.png\"\n",
        "plt.savefig(performance_path, dpi=300)\n",
        "print(f\"Performance test plot saved to: {performance_path}\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✓ All results saved to Google Drive in: {PROJECT_FOLDER}\")"
      ],
      "metadata": {
        "id": "plot_performance"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Monitor Training with TensorBoard\n",
        "\n",
        "Run this cell to visualize training progress in real-time:"
      ],
      "metadata": {
        "id": "tensorboard_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {LOG_DIR}/tb/"
      ],
      "metadata": {
        "id": "tensorboard"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Resume Training from Checkpoint\n",
        "\n",
        "If your session times out, you can resume training:"
      ],
      "metadata": {
        "id": "resume_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List available checkpoints\n",
        "import glob\n",
        "checkpoints = sorted(glob.glob(f\"{SAVE_DIR}/ppo_emergency_lidar_checkpoint_*.zip\"))\n",
        "print(\"Available checkpoints:\")\n",
        "for cp in checkpoints:\n",
        "    print(f\"  {os.path.basename(cp)}\")\n",
        "\n",
        "# Load the latest checkpoint (or specify a specific one)\n",
        "if checkpoints:\n",
        "    latest_checkpoint = checkpoints[-1]\n",
        "    print(f\"\\nLoading: {os.path.basename(latest_checkpoint)}\")\n",
        "    model = PPO.load(latest_checkpoint, env=venv)\n",
        "    \n",
        "    # Continue training\n",
        "    model.learn(\n",
        "        total_timesteps=500_000,\n",
        "        reset_num_timesteps=False,  # Keep existing timestep count\n",
        "        callback=[checkpoint_callback, eval_callback],\n",
        "        progress_bar=True\n",
        "    )\n",
        "else:\n",
        "    print(\"No checkpoints found!\")"
      ],
      "metadata": {
        "id": "resume"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
